{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "0     0.352941  0.743719       0.590164       0.353535  0.000000  0.500745   \n",
      "1     0.058824  0.427136       0.540984       0.292929  0.000000  0.396423   \n",
      "2     0.470588  0.919598       0.524590       0.000000  0.000000  0.347243   \n",
      "3     0.058824  0.447236       0.540984       0.232323  0.111111  0.418778   \n",
      "4     0.000000  0.688442       0.327869       0.353535  0.198582  0.642325   \n",
      "\n",
      "   DiabetesPedigreeFunction       Age  Outcome  \n",
      "0                  0.234415  0.483333      1.0  \n",
      "1                  0.116567  0.166667      0.0  \n",
      "2                  0.253629  0.183333      1.0  \n",
      "3                  0.038002  0.000000      0.0  \n",
      "4                  0.943638  0.200000      1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df= pd.read_csv(filepath_or_buffer=\"D:/Bases_de_datos/input/diabetes.csv\")\n",
    "# Distribución Normal\n",
    "\n",
    "# Inicializa el escalador Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Seleccionar las columnas numéricas para la normalización\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Aplicar la normalización y actualizar el df con las columnas normalizadas\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Muestra las primeras filas del DataFrame normalizado\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrando y practicando con hiperparámetros\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Inicializamos el modelo\n",
    "modelo = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definimos el espacio de hiperparámetros a explorar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Número de árboles\n",
    "    'max_depth': [None, 10, 20, 30],  # Profundidad máxima de los árboles\n",
    "    'min_samples_split': [2, 5, 10],  # Número mínimo de muestras requerido para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4]  # Número mínimo de muestras requerido en cada hoja\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Mejor puntuación (accuracy) durante la validación cruzada: 0.7834199653471945\n",
      "Accuracy en el conjunto de prueba: 0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación (accuracy) durante la validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Utilizar el mejor modelo encontrado para hacer predicciones en el conjunto de prueba\n",
    "mejor_modelo = grid_search.best_estimator_\n",
    "predicciones = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar el accuracy en el conjunto de prueba\n",
    "accuracy_test = accuracy_score(y_test, predicciones)\n",
    "print(\"Accuracy en el conjunto de prueba:\", accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
